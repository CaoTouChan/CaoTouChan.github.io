<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <title>笔记 - CS224U NLU 07 关系抽取</title>
  <meta name="description" content="概要">
  <meta name="author" content="Wei Wang">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="笔记 - CS224U NLU 07 关系抽取">
  <meta name="twitter:description" content="概要">
  
  <meta property="og:type" content="article">
  <meta property="og:title" content="笔记 - CS224U NLU 07 关系抽取">
  <meta property="og:description" content="概要">
  
  <link rel="icon" type="image/png" href="/assets/images/favicon.png" />
  <link href="/assets/images/favicon.png" rel="shortcut icon" type="image/png">
  
  <link rel="stylesheet" href="/css/main.css">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">

  <link rel="canonical" href="http://localhost:4000/2019/07/cs224u-07-re/">
  <link rel="alternate" type="application/rss+xml" title="陈草头" href="http://localhost:4000/feed.xml">
  
  <meta name="google-site-verification" content="1-1ZlHoRvM0T2FqPbW2S-qLgYXN6rsn52kErlMPd_gw" />

  <script src="https://code.jquery.com/jquery-3.3.1.min.js"></script>

  <!-- 数学公式 -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      inlineMath: [['$','$']]
    }
  });
</script>


  
</head>


  <body>

    <span class="mobile btn-mobile-menu">
        <i class="fa fa-list btn-mobile-menu__icon"></i>
        <i class="fa fa-angle-up btn-mobile-close__icon hidden"></i>
    </span>
    
    <header class="panel-cover panel-cover--collapsed" style="background-image: url('/assets/images/background-cover.jpg')">
  <div class="panel-main">

    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        <a href="/#blog" title="前往 陈草头 的主页" class="blog-button"><img src="/assets/images/avatar.jpg" width="80" alt="陈草头 logo" class="panel-cover__logo logo" /></a>
        <h1 class="panel-cover__title panel-title"><a href="/#blog" title="link to homepage for 陈草头" class="blog-button">陈草头</a></h1>
        
        <span class="panel-cover__subtitle panel-subtitle">越名教而任自然</span>
        
        <hr class="panel-cover__divider" />
        <p class="panel-cover__description">90 后 | 广东人 | 现居住于帝都 | 算法攻城狮</p>
        <hr class="panel-cover__divider panel-cover__divider--secondary" />
        
        <!-- 
        <p class="panel-cover__description"><a href="https://caotouchan.tech" target="_blank">我的主页</a></p>
         -->
        
        <div class="navigation-wrapper">
          <div>
            <nav class="cover-navigation cover-navigation--primary">
              <ul class="navigation">
                <li class="navigation__item"><a href="/#blog" title="访问博客" class="blog-button">博客</a></li>
                
              </ul>
            </nav>
          </div>
          
          <div><nav class="cover-navigation navigation--social">
  <ul class="navigation">

  
  <!-- Weibo -->
  <li class="navigation__item">
    <a href="http://weibo.com/lookka520" title="@lookka520 的微博" target="_blank">
      <i class='social fa fa-weibo'></i>
      <span class="label">Weibo</span>
    </a>
  </li>
  

  
  <!-- Github -->
  <li class="navigation__item">
    <a href="https://github.com/caotouchan" title="@caotouchan 的 Github" target="_blank">
      <i class='social fa fa-github'></i>
      <span class="label">Github</span>
    </a>
  </li>
  
  
  

  

  <!-- RSS -->
  <li class="navigation__item">
    <a href="/feed.xml" rel="author" title="RSS" target="_blank">
      <i class='social fa fa-rss'></i>
      <span class="label">RSS</span>
    </a>
  </li>

  
  <!-- Email -->
  <li class="navigation__item">
    <a href="mailto:caotouchan@outlook.com" title="Contact me">
      <i class='social fa fa-envelope'></i>
      <span class="label">Email</span>
    </a>
  </li>
  

  </ul>
</nav>
</div>
        </div>
      </div>
    </div>
    
    
    <div class="panel-cover--overlay cover-red"></div>
    
  </div>
</header>


    <div class="content-wrapper">
        <div class="content-wrapper__inner">
            <article class="post-container post-container--single" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="post-header">
    <div class="post-meta">
      <time datetime="2019-07-01 08:02:11 +0800" itemprop="datePublished" class="post-meta__date date">2019-07-01</time> &#8226; <span class="post-meta__tags tags">cs224u stanford 关系抽取 远程监督</span>
    </div>
    <h1 class="post-title">笔记 - CS224U NLU 07 关系抽取</h1>
  </header>

  <section class="post">
    <h2 id="概要">概要</h2>

<p>关系抽取实际上就是从自然语言文本中抽取出三元组，比如：</p>

<ul>
  <li>(founders, SpaceX, Elon_Musk)</li>
  <li>(has_spouse, Elon_Musk, Talulah_Riley)</li>
  <li>(worked_at, Elon_Musk, Tesla_Motors)</li>
</ul>

<p>累计这些三元组构造的知识库 (knowledge base, KB) 可以作为 QA 系统之类的基础。但是构造 KB 是个费时且昂贵的工作，所以我们将会使用一些现成的 KB 来帮助我们完成这个任务。</p>

<h2 id="基于模板的方法hand-built-patterns">基于模板的方法(Hand-built patterns)</h2>

<h3 id="基于触发词字符串"><strong>基于触发词/字符串</strong></h3>

<p>举例来说，使用类似 “X is the founder of Y” 这样的模板，可以抽取出 IS-A 的关系，比如 “Elon Musk is the founder of SpaceX” 可以得到 <code class="highlighter-rouge">(founders, SpaceX, Elon_Musk)</code> 。</p>

<p>可以使用诸如 Stanford CoreNLP 的 <code class="highlighter-rouge">tokensRegex</code> 这样的工具进行实现。</p>

<h3 id="基于依存句法"><strong>基于依存句法</strong></h3>

<p>通常以动词为起点构建规则，对节点上的词性和边上的依存关系进行限定，流程为：</p>

<ol>
  <li>分词、词性标注、命名实体识别、依存句法分析等</li>
  <li>根据依存句法树匹配规则，生成三元组</li>
  <li>根据扩展规则扩展三元组</li>
  <li>进一步对三元组实体和触发词进行关系抽取</li>
</ol>

<p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4k7qfhdbzj310q0lo0u9.jpg" alt="" /></p>

<p>图片来源：<a href="http://www.shuang0420.com/2018/09/15/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/">徐阿衡的博客</a></p>

<ul>
  <li>优缺点</li>
</ul>

<p>基于模板的方法可以有高准确率，但是召回率会比较高，而且费时费力。</p>

<h2 id="监督学习supervised-machine-learning">监督学习(supervised machine learning)</h2>

<h3 id="机器学习"><strong>机器学习</strong></h3>

<p>为了提高效率，我们训练两个分类器，第一个分类器判断命名实体间是否有关系，若有则送到第二个分类器给实体分配关系类别，分类器可以选择 MaxEnt、Naive Bayes、SVM 等。</p>

<p>特征的选择可以有多样，比如：</p>
<ol>
  <li>轻量级 ：实体的特征，包括实体前后的词、实体类型、实体之间的距离等</li>
  <li>中等量级 ：考虑 chunk，如 NP、VP、PP 这类短语</li>
  <li>重量级 ：考虑实体间的依存关系、实体间树结构的距离、其他特定的结构信息等</li>
</ol>

<h3 id="深度学习pipeline-vs-joint-model"><strong>深度学习（Pipeline vs Joint Model）</strong></h3>

<p>模型通常有 CNN/RNN + attention，损失函数 ranking loss 要优于 cross entropy。</p>

<p>用到的特征通常有：</p>
<ol>
  <li>Position embeddings</li>
  <li>Word embeddings</li>
  <li>Knowledge embeddings</li>
</ol>

<p>分为两大类 Pipeline 和 Joint Model：</p>

<ol>
  <li><strong>Pipeline</strong> ： 把实体识别和关系分类作为两个完全 <strong>独立</strong> 的过程</li>
</ol>

<ul>
  <li>CR-CNN (<a href="https://arxiv.org/pdf/1504.06580.pdf">Santos et. al Computer Science 2015</a>)</li>
</ul>

<p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4k9ojhqv1j308e0epjrm.jpg" alt="" /></p>

<p>word embedding + position embedding、6 个卷积核、max pooling 生成 sentence vector，与关系向量做点积求相似度。</p>

<p>损失函数使用 <strong>pairwise ranking loss function</strong></p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{equation}
\begin{aligned} L=& \log \left(1+\exp \left(\gamma\left(m^{+}-s_{\theta}(x)_{y^{+}}\right)\right)\right.\\ &+\log \left(1+\exp \left(\gamma\left(m^{-}+s_{\theta}(x)_{c^{-}}\right)\right)\right.\end{aligned}
\end{equation} %]]></script>

<p>训练时每个样本有两个标签，正确标签 $y^+$ 和错误标签 $c^-$，$m^+$ 和 $m^-$ 对应了两个 margin，$\gamma$ 用来缩放。希望 <script type="math/tex">s_{\theta}(x)_{y^+}</script> 越大越好，$s_{\theta}(x)_{c^-}$ 越小越好。</p>

<ul>
  <li>Att-CNN (<a href="http://iiis.tsinghua.edu.cn/~weblt/papers/relation-classification.pdf">Relation Classification via Multi-Level Attention CNNs</a>)</li>
</ul>

<p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4k9uunlpgj30nu0gcdh9.jpg" alt="" /></p>

<p>使用两层 Attention —— 一个是对两个实体的注意力，另一个是用 attention pooling 代替 max pooling （加强相关性强的词的权重）。</p>

<ul>
  <li>Att-BLSTM （<a href="http://www.aclweb.org/anthology/P16-2034">Peng Zhou et. al ACL 2016</a>）</li>
</ul>

<p>BiLSTM + Attention 做关系分类任务。</p>

<p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4k9zy9vn2j30vh0ekdgr.jpg" alt="" /></p>

<ul>
  <li>评测</li>
</ul>

<p>各方法在 SemEval-2010 Task 8 上的评测：</p>

<p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4ka1i7hyuj315u0ne0vs.jpg" alt="" /></p>

<ol>
  <li><strong>Joint Model</strong> ：实体识别和关系分类的过程 <strong>共同优化</strong></li>
</ol>

<ul>
  <li>LSTM-RNNs （<a href="https://arxiv.org/pdf/1601.00770.pdf">Miwa et. al ACL 2016</a>)</li>
</ul>

<p>实体识别和关系分类的参数共享，判断过程没有进行交互。</p>

<p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g4ka58dl61j30s90e3q3r.jpg" alt="" /></p>

<p>从上图可以看出有三个表示层：</p>

<blockquote>
  <p>Embedding layer (word embeddings layer) ： 用到词向量、词性标签、依存句法标签、实体标签</p>

  <p>Sequence layer (word sequence based LSTM-RNN layer)：负责实体识别。对两个方向的隐层单元拼接后进行实体识别（或序列标注）</p>

  <p>Dependency layer (dependency subtree based LSTM-RNN layer )：负责关系分类。用 tree-structured BiLSTM-RNNs 来表示 relation candidate，捕捉了 top-down 和 bottom-up 双向的关系。主要是对 sequence layer 识别出的每个实体的最后一个单词进行排列组合，然后同样用两层 NN + softmax 对该组合进行分类。</p>
</blockquote>

<ul>
  <li>评测</li>
</ul>

<p><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g4kat7oqqoj30bj071t8z.jpg" alt="" /></p>

<p>直觉上 pipeline 会传递误差，但是上图表明 Joint Model 未必起作用，但是评测结果表明外部知识可以对训练产生正面影响。</p>

<h2 id="半监督学习">半监督学习</h2>

<p>半监督学习是利用少量的标注信息进行学习，有基于 Bootstrap 的方法以及 <a href="http://deepdive.stanford.edu/distant_supervision">远程监督</a> 方法。</p>

<h3 id="bootstrapping"><strong>Bootstrapping</strong></h3>

<p>用少量实例作为初始种子(seed tuples)的集合，然后利用 pattern 学习方法进行学习，迭代抽取实例，然后从新实例中学习新 pattern 并扩充 pattern 集合，寻找和发现新的潜在关系三元组。</p>

<p><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g4kb9ab0ljj30sc0gzdhp.jpg" alt="" /></p>

<p>这方法对初始给定的种子集敏感，存在语义漂移问题，准确率较低，缺乏对每一个结果的置信度的计算。</p>

<h3 id="distant-supervision"><strong>Distant supervision</strong></h3>

<p>把知识库与非结构化文本对齐来自动构建大量训练数据，减少模型对人工标注数据的依赖。先从知识库中抽取存在关系的实体对，然后从非结构化文本中抽取含有实体对的句子作为训练样本，提取特征训练分类器。</p>

<ul>
  <li>APCNNs (PCNN + Sentence-level Attention) （<a href="https://pdfs.semanticscholar.org/b8da/823ad81e3b8e5b80d82f86129fdb1d9132e7.pdf?_ga=2.214235987.519572625.1561962607-1203158446.1561962607">Kang Liu et.al AI 2017</a>）</li>
</ul>

<p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g4kbqekmqmj30sw0cygms.jpg" alt="" /></p>

<ol>
  <li>PCNN : 分段池化以更加精准刻画不同上下文对句向量的贡献，参考 <a href="http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP203.pdf">Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks</a>。</li>
  <li>Sentence-level Attention : 句子层面的 attention 对 bag 里所有句子进行加权作为 bag 的特征向量，参考 <a href="http://www.aclweb.org/anthology/P16-1200">Neural Relation Extraction with Selective Attention over Instances</a>。权重公式 ： <script type="math/tex">\begin{equation}
\omega_{i}=\mathbf{W}_{a}^{\top}\left(\tanh \left[\boldsymbol{b}_{i} ; \boldsymbol{v}_{\text {relation}}\right]\right)+b_{a}
\end{equation}</script>，这里对两个实体向量作差来表示关系向量 <script type="math/tex">v_{relation}</script>，如果一个 instance 能表达这种关系，那么这个 instance 的向量表达应该和 <script type="math/tex">v_{relation}</script> 高度相似，根据这个假设来计算句向量和关系向量的相关性。</li>
  <li>Entity Descriptions : 引入实体背景知识 <script type="math/tex">\begin{equation}
\mathcal{D}=\left\{\left(e_{i}, d_{i}\right)|i=1, \cdots,| \mathcal{D} |\right\}
\end{equation}</script> （其中，<script type="math/tex">e_i</script> 是实体表示，<script type="math/tex">d_i</script> 是通过另一个传统 CNN 对收集到的实体的描述句抽特征得到），定义误差 <script type="math/tex">\begin{equation}
\mathcal{L}_{e}=\sum_{i=1}^{|\mathcal{D}|}\left\|\boldsymbol{e}_{i}-\boldsymbol{d}_{i}\right\|_{2}^{2}
\end{equation}</script>。</li>
</ol>

<p>训练过程是先训练不包含 Entity Descriptions 的 APCNNs 模型，目标函数是 <script type="math/tex">\begin{equation}
\min \mathcal{L}_{A}=-\sum_{i=1}^{N} \log p\left(r_{i} | B_{i}, \theta\right)
\end{equation}</script>。然后训练模型 APCNNs + D，目标函数是 <script type="math/tex">\begin{equation}
\min \mathcal{L}=\mathcal{L}_{A}+\lambda \mathcal{L}_{e}
\end{equation}</script>。</p>

<p>这种方法可以利用丰富的知识库信息，但因为其过强的假设导入引入大量噪声，也存在语义漂移，很难发现新的关系。</p>

<h2 id="无监督学习">无监督学习</h2>

<h3 id="unsupervised-learning-from-the-web"><strong>Unsupervised learning from the web</strong></h3>

<h2 id="参考资料和相关阅读">参考资料和相关阅读</h2>

<ul>
  <li>
    <p>Stanford CS224U 课程主页 <a href="http://web.stanford.edu/class/cs224u/">http://web.stanford.edu/class/cs224u/</a></p>
  </li>
  <li>
    <p>CS224U NLU（ 07 ）：关系抽取 视频 <a href="https://youtu.be/pO3Jsr31s_Q">https://youtu.be/pO3Jsr31s_Q</a></p>
  </li>
  <li>
    <p>Jurafsky and Martin 2009, §22.1-22.2 <a href="http://web.stanford.edu/class/cs224u/restricted/JM2009infoextract.pdf">http://web.stanford.edu/class/cs224u/restricted/JM2009infoextract.pdf</a></p>
  </li>
  <li>
    <p>Snow et al. 2005 <a href="http://ai.stanford.edu/~rion/papers/hypernym_nips05.pdf">http://ai.stanford.edu/~rion/papers/hypernym_nips05.pdf</a></p>
  </li>
  <li>
    <p>Mintz et al. 2009 <a href="http://www.aclweb.org/anthology/P/P09/P09-1113.pdf">http://www.aclweb.org/anthology/P/P09/P09-1113.pdf</a></p>
  </li>
  <li>
    <p>徐啊衡 知识抽取-实体及关系抽取 <a href="http://www.shuang0420.com/2018/09/15/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/">http://www.shuang0420.com/2018/09/15/知识抽取-实体及关系抽取</a></p>
  </li>
</ul>


  </section>
</article>

<section class="read-more">
   
   
   
   
   <div class="read-more-item">
       <span class="read-more-item-dim">更早的文章</span>
       <h2 class="post-list__post-title post-title"><a href="/2019/06/kafka-01-intro/" title="link to Kafka 知识总结与实战（01）消息引擎、分布式流处理平台、基本术语">Kafka 知识总结与实战（01）消息引擎、分布式流处理平台、基本术语</a></h2>
       <p class="excerpt">&hellip;</p>
       <div class="post-list__meta"><time datetime="2019-06-30 14:02:11 +0800" class="post-list__meta--date date">2019-06-30</time> &#8226; <span class="post-list__meta--tags tags">消息引擎 分布式流处理平台 消息 主题 生产者 消费者 重平衡</span><a class="btn-border-small" href=/2019/06/kafka-01-intro/>继续阅读</a></div>
   </div>
   
</section>

<section class="post-comments">
  

  

  <!-- Gitalk 评论 start  -->
  
    <!-- Link Gitalk 的支持文件  -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
  <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>

    <div id="gitalk-container"></div>

    <script type="text/javascript">
      var gitalk = new Gitalk({
        clientID: '6005df5e831456f4482b',
        clientSecret: 'ffc57d242198e14cdb68b7457a765d0b719415fb',
        repo: 'caotouchan.github.io',
        owner: 'CaoTouChan',
        admin: ['CaoTouChan'],
        id: window.location.pathname,
      });
      gitalk.render('gitalk-container');
    </script>
  
  <!-- Gitalk end -->
</section>


            <section class="footer">
    <footer>
    	<span class="footer__copyright">本站点采用<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享 署名-非商业性使用-相同方式共享 4.0 国际 许可协议</a></span>
        <span class="footer__copyright">本站由 <a href="https://caotouchan.tech">@caotouchan</a> 创建，采用 <a href="https://github.com/onevcat/vno-jekyll">Vno - Jekyll</a> 作为主题，您可以在 GitHub 找到<a href="https://github.com/CaoTouChan/caotouchan.github.io">本站源码</a> - &copy; 2019</span>
    </footer>
</section>

        </div>
    </div>
    
    <script type="text/javascript" src="//code.jquery.com/jquery-1.11.3.min.js"></script>

<script type="text/javascript" src="/js/main.js"></script>



    
  </body>

</html>
